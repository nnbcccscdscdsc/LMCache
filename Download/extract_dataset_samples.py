#!/usr/bin/env python3
"""
æ•°æ®é›†æ ·æœ¬æŠ½å–è„šæœ¬
ä»å››ä¸ªæ•°æ®é›†ä¸­æŠ½å–æŒ‡å®šæ•°é‡çš„æµ‹è¯•ç”¨ä¾‹ï¼š
- 2WikiMQA: 200 ä¸ªæµ‹è¯•ç”¨ä¾‹
- Musique: 150 ä¸ªæµ‹è¯•ç”¨ä¾‹  
- SAMSum: 200 ä¸ªæµ‹è¯•ç”¨ä¾‹
- MultiNews: 60 ä¸ªæŠ½æ ·ç”¨ä¾‹
python extract_dataset_samples.py --2wikimqa 200 --musique 150 --samsum 200 --multinews 60 --output-dir ./test_samples
"""

import os
import json
import random
from pathlib import Path
from datasets import load_dataset
import argparse

def set_random_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯å¤ç°"""
    random.seed(seed)
    print(f"ğŸ² è®¾ç½®éšæœºç§å­: {seed}")

def extract_2wikimqa_samples(num_samples=200):
    """ä» 2WikiMQA æ•°æ®é›†ä¸­æŠ½å–æ ·æœ¬"""
    print(f"ğŸ“Š æ­£åœ¨ä» 2WikiMQA æ•°æ®é›†ä¸­æŠ½å– {num_samples} ä¸ªæ ·æœ¬...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset('presencesw/complexquestion_2WIKIMQA_1000')
        
        # è·å–æµ‹è¯•é›†
        if 'test' in dataset:
            test_data = dataset['test']
        elif 'validation' in dataset:
            test_data = dataset['validation']
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æµ‹è¯•é›†ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„åˆ†å‰²
            test_data = dataset[list(dataset.keys())[0]]
        
        total_samples = len(test_data)
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        
        if total_samples < num_samples:
            print(f"   âš ï¸  è­¦å‘Š: æ•°æ®é›†åªæœ‰ {total_samples} ä¸ªæ ·æœ¬ï¼Œå°‘äºè¯·æ±‚çš„ {num_samples} ä¸ª")
            num_samples = total_samples
        
        # éšæœºæŠ½å–æ ·æœ¬
        indices = random.sample(range(total_samples), num_samples)
        selected_samples = [test_data[i] for i in indices]
        
        print(f"   âœ… æˆåŠŸæŠ½å– {len(selected_samples)} ä¸ªæ ·æœ¬")
        return selected_samples
        
    except Exception as e:
        print(f"   âŒ åŠ è½½ 2WikiMQA æ•°æ®é›†å¤±è´¥: {e}")
        return []

def extract_musique_samples(num_samples=150):
    """ä» Musique æ•°æ®é›†ä¸­æŠ½å–æ ·æœ¬"""
    print(f"ğŸ“Š æ­£åœ¨ä» Musique æ•°æ®é›†ä¸­æŠ½å– {num_samples} ä¸ªæ ·æœ¬...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset('dgslibisey/MuSiQue')
        
        # è·å–æµ‹è¯•é›†
        if 'test' in dataset:
            test_data = dataset['test']
        elif 'validation' in dataset:
            test_data = dataset['validation']
        else:
            test_data = dataset[list(dataset.keys())[0]]
        
        total_samples = len(test_data)
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        
        if total_samples < num_samples:
            print(f"   âš ï¸  è­¦å‘Š: æ•°æ®é›†åªæœ‰ {total_samples} ä¸ªæ ·æœ¬ï¼Œå°‘äºè¯·æ±‚çš„ {num_samples} ä¸ª")
            num_samples = total_samples
        
        # éšæœºæŠ½å–æ ·æœ¬
        indices = random.sample(range(total_samples), num_samples)
        selected_samples = [test_data[i] for i in indices]
        
        print(f"   âœ… æˆåŠŸæŠ½å– {len(selected_samples)} ä¸ªæ ·æœ¬")
        return selected_samples
        
    except Exception as e:
        print(f"   âŒ åŠ è½½ Musique æ•°æ®é›†å¤±è´¥: {e}")
        return []

def extract_samsum_samples(num_samples=200):
    """ä» SAMSum æ•°æ®é›†ä¸­æŠ½å–æ ·æœ¬"""
    print(f"ğŸ“Š æ­£åœ¨ä» SAMSum æ•°æ®é›†ä¸­æŠ½å– {num_samples} ä¸ªæ ·æœ¬...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset('knkarthick/samsum')
        
        # è·å–æµ‹è¯•é›†
        if 'test' in dataset:
            test_data = dataset['test']
        elif 'validation' in dataset:
            test_data = dataset['validation']
        else:
            test_data = dataset[list(dataset.keys())[0]]
        
        total_samples = len(test_data)
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        
        if total_samples < num_samples:
            print(f"   âš ï¸  è­¦å‘Š: æ•°æ®é›†åªæœ‰ {total_samples} ä¸ªæ ·æœ¬ï¼Œå°‘äºè¯·æ±‚çš„ {num_samples} ä¸ª")
            num_samples = total_samples
        
        # éšæœºæŠ½å–æ ·æœ¬
        indices = random.sample(range(total_samples), num_samples)
        selected_samples = [test_data[i] for i in indices]
        
        print(f"   âœ… æˆåŠŸæŠ½å– {len(selected_samples)} ä¸ªæ ·æœ¬")
        return selected_samples
        
    except Exception as e:
        print(f"   âŒ åŠ è½½ SAMSum æ•°æ®é›†å¤±è´¥: {e}")
        return []

def extract_multinews_samples(num_samples=60):
    """ä» MultiNews æ•°æ®é›†ä¸­æŠ½å–æ ·æœ¬"""
    print(f"ğŸ“Š æ­£åœ¨ä» MultiNews æ•°æ®é›†ä¸­æŠ½å– {num_samples} ä¸ªæ ·æœ¬...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset('Awesome075/multi_news_parquet')
        
        # è·å–æµ‹è¯•é›†
        if 'test' in dataset:
            test_data = dataset['test']
        elif 'validation' in dataset:
            test_data = dataset['validation']
        else:
            test_data = dataset[list(dataset.keys())[0]]
        
        total_samples = len(test_data)
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        
        if total_samples < num_samples:
            print(f"   âš ï¸  è­¦å‘Š: æ•°æ®é›†åªæœ‰ {total_samples} ä¸ªæ ·æœ¬ï¼Œå°‘äºè¯·æ±‚çš„ {num_samples} ä¸ª")
            num_samples = total_samples
        
        # éšæœºæŠ½å–æ ·æœ¬
        indices = random.sample(range(total_samples), num_samples)
        selected_samples = [test_data[i] for i in indices]
        
        print(f"   âœ… æˆåŠŸæŠ½å– {len(selected_samples)} ä¸ªæ ·æœ¬")
        return selected_samples
        
    except Exception as e:
        print(f"   âŒ åŠ è½½ MultiNews æ•°æ®é›†å¤±è´¥: {e}")
        return []

def save_samples_to_file(samples, dataset_name, output_dir):
    """ä¿å­˜æŠ½å–çš„æ ·æœ¬åˆ°æ–‡ä»¶"""
    output_path = output_dir / f"{dataset_name}_samples.json"
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(samples, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ æ ·æœ¬å·²ä¿å­˜åˆ°: {output_path}")
        return output_path
    except Exception as e:
        print(f"   âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description="ä»å››ä¸ªæ•°æ®é›†ä¸­æŠ½å–æŒ‡å®šæ•°é‡çš„æµ‹è¯•ç”¨ä¾‹")
    parser.add_argument("--output-dir", default="./extracted_samples", help="è¾“å‡ºç›®å½• (é»˜è®¤: ./extracted_samples)")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­ (é»˜è®¤: 42)")
    parser.add_argument("--2wikimqa", type=int, default=200, help="2WikiMQA æ ·æœ¬æ•°é‡ (é»˜è®¤: 200)")
    parser.add_argument("--musique", type=int, default=150, help="Musique æ ·æœ¬æ•°é‡ (é»˜è®¤: 150)")
    parser.add_argument("--samsum", type=int, default=200, help="SAMSum æ ·æœ¬æ•°é‡ (é»˜è®¤: 200)")
    parser.add_argument("--multinews", type=int, default=60, help="MultiNews æ ·æœ¬æ•°é‡ (é»˜è®¤: 60)")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    print("ğŸš€ å¼€å§‹æŠ½å–æ•°æ®é›†æ ·æœ¬")
    print("=" * 50)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ² éšæœºç§å­: {args.seed}")
    print()
    
    # è®¾ç½®éšæœºç§å­
    set_random_seed(args.seed)
    
    # æŠ½å–å„æ•°æ®é›†çš„æ ·æœ¬
    results = {}
    
    # 1. 2WikiMQA
    print("1ï¸âƒ£ å¤„ç† 2WikiMQA æ•°æ®é›†")
    print("-" * 30)
    wikimqa_samples = extract_2wikimqa_samples(getattr(args, '2wikimqa'))
    if wikimqa_samples:
        save_samples_to_file(wikimqa_samples, "2WikiMQA", output_dir)
        results["2WikiMQA"] = len(wikimqa_samples)
    print()
    
    # 2. Musique
    print("2ï¸âƒ£ å¤„ç† Musique æ•°æ®é›†")
    print("-" * 30)
    musique_samples = extract_musique_samples(getattr(args, 'musique'))
    if musique_samples:
        save_samples_to_file(musique_samples, "Musique", output_dir)
        results["Musique"] = len(musique_samples)
    print()
    
    # 3. SAMSum
    print("3ï¸âƒ£ å¤„ç† SAMSum æ•°æ®é›†")
    print("-" * 30)
    samsum_samples = extract_samsum_samples(getattr(args, 'samsum'))
    if samsum_samples:
        save_samples_to_file(samsum_samples, "SAMSum", output_dir)
        results["SAMSum"] = len(samsum_samples)
    print()
    
    # 4. MultiNews
    print("4ï¸âƒ£ å¤„ç† MultiNews æ•°æ®é›†")
    print("-" * 30)
    multinews_samples = extract_multinews_samples(getattr(args, 'multinews'))
    if multinews_samples:
        save_samples_to_file(multinews_samples, "MultiNews", output_dir)
        results["MultiNews"] = len(multinews_samples)
    print()
    
    # æ€»ç»“
    print("ğŸ“‹ æŠ½å–ç»“æœæ€»ç»“")
    print("=" * 30)
    total_samples = 0
    for dataset_name, count in results.items():
        print(f"âœ… {dataset_name}: {count} ä¸ªæ ·æœ¬")
        total_samples += count
    
    print(f"ğŸ“Š æ€»è®¡: {total_samples} ä¸ªæ ·æœ¬")
    print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    
    # ä¿å­˜æ€»ç»“ä¿¡æ¯
    summary = {
        "extraction_date": str(Path().cwd()),
        "random_seed": args.seed,
        "output_directory": str(output_dir),
        "results": results,
        "total_samples": total_samples
    }
    
    summary_path = output_dir / "extraction_summary.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æ€»ç»“ä¿¡æ¯å·²ä¿å­˜åˆ°: {summary_path}")

if __name__ == "__main__":
    main()
